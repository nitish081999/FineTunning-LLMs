{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6edc7eef335f448bb927de6953e1f8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac6ff13d688742aabc2f05a3bd22d994",
              "IPY_MODEL_94c7f2ad86a149efa5e71774336eeb6c",
              "IPY_MODEL_61b6dcfeefc54856bc360d5453f1c0ad"
            ],
            "layout": "IPY_MODEL_e31e7abbb82f45ae864801eaa5b02fec"
          }
        },
        "ac6ff13d688742aabc2f05a3bd22d994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eac4b2cb11084f0c8b9727c428816e19",
            "placeholder": "​",
            "style": "IPY_MODEL_f4d6fc67e0d241ee95ae53b681b76717",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "94c7f2ad86a149efa5e71774336eeb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8ee77db55044de48e1eb6fe2c714f09",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb14f3ec970b4cedb23037491a6b0cb4",
            "value": 2
          }
        },
        "61b6dcfeefc54856bc360d5453f1c0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6219464143094fc3a63a19cfa8bf30b3",
            "placeholder": "​",
            "style": "IPY_MODEL_0e0480a40129497780f45f3becb15a6f",
            "value": " 2/2 [01:08&lt;00:00, 31.45s/it]"
          }
        },
        "e31e7abbb82f45ae864801eaa5b02fec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eac4b2cb11084f0c8b9727c428816e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4d6fc67e0d241ee95ae53b681b76717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8ee77db55044de48e1eb6fe2c714f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb14f3ec970b4cedb23037491a6b0cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6219464143094fc3a63a19cfa8bf30b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e0480a40129497780f45f3becb15a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "644909dde9e1499b81def1faababbfb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b85213e0786c4e2faf4f887ec7d9f691",
              "IPY_MODEL_e966f152b7f7490a9b1ee794e61e77ae",
              "IPY_MODEL_e974821290ea48ea9b298c3d990396d0"
            ],
            "layout": "IPY_MODEL_d46a0b4d712c40859f221aac9967d262"
          }
        },
        "b85213e0786c4e2faf4f887ec7d9f691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_effa63f716b34dfeaa875354b39d5fed",
            "placeholder": "​",
            "style": "IPY_MODEL_64b471c4794b471397819a138d342305",
            "value": "Map: 100%"
          }
        },
        "e966f152b7f7490a9b1ee794e61e77ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bc8b8e6b9024c088c9bb53452923593",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_291dfadcefba41369078dd446a35d090",
            "value": 1000
          }
        },
        "e974821290ea48ea9b298c3d990396d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53e6486bdf6f474c882ffd4e322bcfff",
            "placeholder": "​",
            "style": "IPY_MODEL_ee53a311364f404db8997e999221f2e0",
            "value": " 1000/1000 [00:01&lt;00:00, 990.83 examples/s]"
          }
        },
        "d46a0b4d712c40859f221aac9967d262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "effa63f716b34dfeaa875354b39d5fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b471c4794b471397819a138d342305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bc8b8e6b9024c088c9bb53452923593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "291dfadcefba41369078dd446a35d090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53e6486bdf6f474c882ffd4e322bcfff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee53a311364f404db8997e999221f2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MJAV5tsy1jH"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 bitsandbytes==0.40.2 peft==0.4.0 transformers==4.31.0 trl==0.4.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import os\n",
        " import torch\n",
        " from datasets import load_dataset\n",
        " from transformers import (\n",
        "     AutoModelForCausalLM,\n",
        "     AutoTokenizer,\n",
        "     BitsAndBytesConfig,\n",
        "     HfArgumentParser,\n",
        "     TrainingArguments,\n",
        "     pipeline,\n",
        "     logging,\n",
        " )\n",
        " from peft import LoraConfig, PeftModel\n",
        " from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "kXapd8IAzLPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In Case of Llama 2, the following prompt template is used for the chat models\n",
        "#<S>[INST]<<SYS>>System Prompt<</SYS>>User Prompt[/INST]Model Answer</S>"
      ],
      "metadata": {
        "id": "w7QDhfvW0J7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "5iaCjXAs14QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "dataset=load_dataset('timdettmers/openassistant-guanaco')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBfgv9qc17W1",
        "outputId": "8ccc0fa5-3d24-4b05-9493-c849d8a8c3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr0GCmCG17Z2",
        "outputId": "ceb0a4c0-c114-47d5-b12c-bce64404a05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 9846\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 518\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN3-Kn2R17cd",
        "outputId": "cac195ba-fb4d-4230-8cd0-def81ff60955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.dataset_dict.DatasetDict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DyhJBuz17fF",
        "outputId": "550a2678-2660-4a5c-c6fc-ef6017445410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': '### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'].num_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28aF88u924y4",
        "outputId": "49cebede-70d3-4e6a-dee6-c76358ead5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the dataset and slice it\n",
        "dataset=dataset['train'].shuffle(seed=42).select(range(1000))"
      ],
      "metadata": {
        "id": "NuktpYRr17hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a function to transform the data\n",
        "def transform_conversation(example):\n",
        "  conversation_text=example['text']\n",
        "  segments=conversation_text.split('###')\n",
        "\n",
        "  reformatted_segments=[]\n",
        "\n",
        "  #iterate over pair of segments\n",
        "  for i in range(1,len(segments)-1,2):\n",
        "    human_text=segments[i].strip().replace('Human:','').strip()\n",
        "\n",
        "    #check if there is a corresponding assistance segemnt before processing\n",
        "\n",
        "    if i+1<len(segments):\n",
        "      assistance_text=segments[i+1].strip().replace('Assistant:','').strip()\n",
        "\n",
        "      #Apply the new template\n",
        "      reformatted_segments.append(f'<s>[INT] {human_text} [/INT] {assistance_text} </s>')\n",
        "    else:\n",
        "      #Handle the case where there is a no corresponding assistant segment\n",
        "      reformatted_segments.append(f'<s>[INT] {human_text} [/INT] </s>')\n",
        "\n",
        "  return {'text':''.join(reformatted_segments)}\n",
        "\n",
        "\n",
        "transformed_dataset=dataset.map(transform_conversation)\n"
      ],
      "metadata": {
        "id": "-9o8pAfQ17kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How to fine tune Llama 2"
      ],
      "metadata": {
        "id": "vUVAu4H_17m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Full fine-tunning is not possible here: we need parameter-efficient fine-tunning(PEFT) technique like LoRA or QLoRA\n",
        "#To drastically reduce the VRAM usage, we must fine-tune the model in 4-bit precision which is why we'll use QLoRA here"
      ],
      "metadata": {
        "id": "VAeT-cap17pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load a llama-2-7b-chat-hf model(chat model)\n",
        "# Train it on the mlabonne/guanaco-llama2-1k(1,000 samples) which will produce our fine-tuned model Llama-2-7b-chat-finetune\n",
        "# QLoRA will use a rank of 64 with a scaling parameter of 16. we'll load the llama 2 model directly in 4-bit precision using the NF4 type and train it for one epoch"
      ],
      "metadata": {
        "id": "uANW58pN17sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The model we want to train from the Hugging Face hub\n",
        "\n",
        "model_name=\"NousResearch/Llama-2-7b-chat-hf\"\n",
        "\n",
        "#The instruction dataset to use\n",
        "\n",
        "dataset_name='mlabonne/guanaco-llama2-1k'\n",
        "\n",
        "#Fine-tuned model_name\n",
        "new_model='Llama-2-7b-chat-finetune'\n",
        "\n",
        "#QLoRA parameters\n",
        "\n",
        "# LoRA attention dimension\n",
        "\n",
        "lora_r=64\n",
        "\n",
        "#LoRA alpha parameter\n",
        "\n",
        "lora_alpha=16\n",
        "\n",
        "#Dropout probability for LoRA layers\n",
        "\n",
        "lora_dropout=0.1\n",
        "\n",
        "# bitsandbytes parameters\n",
        "\n",
        "#Activate 4-bit precision base model loading\n",
        "use_4bit=True\n",
        "\n",
        "#Quantization type(fp4 or nf4)\n",
        "bnb_4bit_compute_dtype='float16'\n",
        "\n",
        "bnb_4bit_quant_type='nf4'\n",
        "\n",
        "# Activate nested quantization for 4-bit base models (double quantization)\n",
        "\n",
        "use_nested_quant=False\n",
        "\n",
        "#TrainingArguments parameters\n",
        "\n",
        "#Output directory where the model predictions and checkpoints will be stored\n",
        "\n",
        "output_dir='./results'\n",
        "\n",
        "#Number of training epochs\n",
        "\n",
        "num_train_epochs=1\n",
        "\n",
        "#Enable fp16/bf16 training (set bf16 to True with an A100)\n",
        "\n",
        "fp16=False\n",
        "\n",
        "bf16=False\n",
        "\n",
        "#Batch size per GPU for training\n",
        "\n",
        "per_device_train_batch_size=4\n",
        "\n",
        "#Batch size per GPU for evaluation\n",
        "per_device_eval_batch_size=4\n",
        "\n",
        "#Gradient accumulation steps\n",
        "\n",
        "gradient_accumulation_steps=1\n",
        "\n",
        "#Enable gradient checkpointing\n",
        "\n",
        "gradient_checkpointing=True\n",
        "\n",
        "#Maximum gradient normal (gradient clipping)\n",
        "\n",
        "max_grad_norm=0.3\n",
        "\n",
        "#Initially learning rate (AdamW optimizer)\n",
        "learning_rate=2e-4\n",
        "\n",
        "#Weight decay to apply to all layers except bias/LayerNorm weights\n",
        "\n",
        "weight_decay=0.001\n",
        "\n",
        "# Optimizer to use\n",
        "optim = 'paged_adamw_32bit'\n",
        "\n",
        "# Learning rate schedule\n",
        "lr_scheduler_type = 'cosine'\n",
        "\n",
        "# Number of training steps (overrides num_train_epochs)\n",
        "max_steps = -1\n",
        "\n",
        "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
        "warmup_ratio = 0.03\n",
        "\n",
        "# group sequences into batches with same length\n",
        "# Saves memory and speeds up training considerably\n",
        "\n",
        "group_by_length = True\n",
        "\n",
        "# Save checkpoint every X updates steps\n",
        "save_steps = 0\n",
        "\n",
        "# Log every X updates steps\n",
        "logging_steps = 25\n",
        "\n",
        "# Maximum sequence length to use\n",
        "max_seq_length=None\n",
        "\n",
        "# Pack multiple short examples in the same input sequence to increase efficiency\n",
        "packing=False\n",
        "\n",
        "# Load the entire model on the GPU 0\n",
        "\n",
        "device_map='auto'\n",
        "\n"
      ],
      "metadata": {
        "id": "KnQv0p6F17uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load everything and start the fine-tuning process"
      ],
      "metadata": {
        "id": "B5dKmry-17xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#(Load the dataset)\n",
        "dataset=load_dataset(dataset_name,split='train')\n",
        "\n",
        "# Load tokenizer and model with ALoRA configuration\n",
        "\n",
        "compute_dtype=getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "bnb_config=BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "\n",
        "#check GPU compatibility with bfloat16\n",
        "\n",
        "if compute_dtype==torch.float16 and use_4bit:\n",
        "  major, _ = torch.cuda.get_device_capability()\n",
        "  if major >= 8:\n",
        "    print('Your GPU supports bfloat16: accelerate training with bf16=True')\n",
        "\n",
        "\n",
        "#Load base model\n",
        "\n",
        "model=AutoModelForCausalLM.from_pretrained(\n",
        "    model,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "6edc7eef335f448bb927de6953e1f8df",
            "ac6ff13d688742aabc2f05a3bd22d994",
            "94c7f2ad86a149efa5e71774336eeb6c",
            "61b6dcfeefc54856bc360d5453f1c0ad",
            "e31e7abbb82f45ae864801eaa5b02fec",
            "eac4b2cb11084f0c8b9727c428816e19",
            "f4d6fc67e0d241ee95ae53b681b76717",
            "b8ee77db55044de48e1eb6fe2c714f09",
            "bb14f3ec970b4cedb23037491a6b0cb4",
            "6219464143094fc3a63a19cfa8bf30b3",
            "0e0480a40129497780f45f3becb15a6f"
          ]
        },
        "id": "vx98RvTZ170P",
        "outputId": "f9ad17dd-6eab-429c-99dd-e5855eacbe6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6edc7eef335f448bb927de6953e1f8df"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache=False\n",
        "model.config.pretraining_tp=1\n",
        "\n",
        "#Load LLaMA tokenizer\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_name,trust_remote_code=True)\n",
        "tokenizer.pad_token=tokenizer.eos_token\n",
        "tokenizer.padding_side='right' #Fix weired overflow issuse with fp16 training\n",
        "\n",
        "# Load LoRA configuration\n",
        "\n",
        "peft_config=LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias='none',\n",
        "    task_type='CAUSAL_LM'\n",
        ")\n",
        "\n",
        "training_arguments= TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to='tensorboard'\n",
        ")\n",
        "\n",
        "# Set supervised fine-tuning parameters\n",
        "\n",
        "trainer=SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=transformed_dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field='text',\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing\n",
        ")\n",
        "\n",
        "#Train model\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "#Save trained model\n",
        "\n",
        "trainer.model.save_pretrained(new_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570,
          "referenced_widgets": [
            "644909dde9e1499b81def1faababbfb1",
            "b85213e0786c4e2faf4f887ec7d9f691",
            "e966f152b7f7490a9b1ee794e61e77ae",
            "e974821290ea48ea9b298c3d990396d0",
            "d46a0b4d712c40859f221aac9967d262",
            "effa63f716b34dfeaa875354b39d5fed",
            "64b471c4794b471397819a138d342305",
            "1bc8b8e6b9024c088c9bb53452923593",
            "291dfadcefba41369078dd446a35d090",
            "53e6486bdf6f474c882ffd4e322bcfff",
            "ee53a311364f404db8997e999221f2e0"
          ]
        },
        "id": "VcIqETZ518DW",
        "outputId": "894be75f-1b94-40ec-b36f-8998fb2975d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "644909dde9e1499b81def1faababbfb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 27:32, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.401000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.656600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.212800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.444800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.178900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.366000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.468000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>1.158100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.545700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(new_model)"
      ],
      "metadata": {
        "id": "VDQH6FmSbtL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "#Run text generation pipeline with our new model\n",
        "\n",
        "prompt=\"What is Economics ?\"\n",
        "\n",
        "pipe=pipeline(task='text-generation',model=model,tokenizer=tokenizer,max_length=200)\n",
        "result=pipe(f'<s>[INST] {prompt} [/INST]')\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQRTzZDfbtPK",
        "outputId": "8341ebf2-1a40-4878-860a-41743f2b5ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] What is Economics ? [/INST] Economics is the social science that studies the production, distribution, exchange, and consumption of goods and services. It examines how individuals, businesses, governments, and other organizations make decisions about how to allocate resources and how to distribute goods and services.\n",
            "\n",
            "Economics is divided into several branches, including:\n",
            "\n",
            "1. Microeconomics: This branch of economics studies the behavior of individual consumers and firms in making decisions about how to allocate resources and how to produce goods and services.\n",
            "2. Macroeconomics: This branch of economics studies the overall performance of an economy, including factors such as economic growth, inflation, and unemployment.\n",
            "3. International economics: This branch of economics studies the interactions between countries and the global economy.\n",
            "4. Development economics: This branch of economics studies the economic development of countries and the factors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jitIDRXLbtS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S9Ay5AYUbtWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cvq-0DBRbtYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PzeBDTSvbtco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0HVWLEppbtfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jbo2YEVWbtip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qGyVVZ1JbtlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9K6uNd4fbtou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ti171msibtsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yskhARs2btzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sklns1_ubt2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VEVlZDrxbt5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OD1eGHiSbt83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P-2uD6jbbuAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IjC7GMfV0YOO"
      }
    }
  ]
}